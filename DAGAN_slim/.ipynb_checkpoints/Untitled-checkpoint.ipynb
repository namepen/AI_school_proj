{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.zeros(shape=[16,28,28,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " z_input = tf.random_normal([16, 100], mean=0, stddev=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(network_variables, name):\n",
    "    \"\"\"\n",
    "    This method counts the tota\n",
    "    l number of unique parameters for a list of variable objects\n",
    "    :param network_variables: A list of tf network variable objects\n",
    "    :param name: Name of the network\n",
    "    \"\"\"\n",
    "    total_parameters = 0\n",
    "    for variable in network_variables:\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parametes = 1\n",
    "        for dim in shape:\n",
    "            variable_parametes *= dim.value\n",
    "\n",
    "        total_parameters += variable_parametes\n",
    "    print(name, total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(input_features):\n",
    "    \"\"\"\n",
    "    Remove duplicate entries from layer list.\n",
    "    :param input_features: A list of layers\n",
    "    :return: Returns a list of unique feature tensors (i.e. no duplication).\n",
    "    \"\"\"\n",
    "    feature_name_set = set()\n",
    "    non_duplicate_feature_set = []\n",
    "    for feature in input_features:\n",
    "        if feature.name not in feature_name_set:\n",
    "            non_duplicate_feature_set.append(feature)\n",
    "        feature_name_set.add(feature.name)\n",
    "    return non_duplicate_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(output):\n",
    "    if output.get_shape()[3] == 320:\n",
    "        print('outputs = 320, out : ', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UResNetGenerator:\n",
    "    def __init__(self, layer_sizes, layer_padding, batch_size, num_channels=1,\n",
    "                 inner_layers=0, name=\"g\"):\n",
    "        \"\"\"\n",
    "        Initialize a UResNet generator.\n",
    "        :param layer_sizes: A list with the filter sizes for each MultiLayer e.g. [64, 64, 128, 128]\n",
    "        :param layer_padding: A list with the padding type for each layer e.g. [\"SAME\", \"SAME\", \"SAME\", \"SAME\"]\n",
    "        :param batch_size: An integer indicating the batch size\n",
    "        :param num_channels: An integer indicating the number of input channels\n",
    "        :param inner_layers: An integer indicating the number of inner layers per MultiLayer\n",
    "        \"\"\"\n",
    "        self.reuse = False\n",
    "        self.batch_size = batch_size\n",
    "        self.num_channels = num_channels\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.layer_padding = layer_padding\n",
    "        self.inner_layers = inner_layers\n",
    "        self.conv_layer_num = 0\n",
    "        self.build = True\n",
    "        self.name = name\n",
    "\n",
    "    def upscale(self, x, h_size, w_size):\n",
    "        \"\"\"\n",
    "        Upscales an image using nearest neighbour\n",
    "        :param x: Input image\n",
    "        :param h_size: Image height size\n",
    "        :param w_size: Image width size\n",
    "        :return: Upscaled image\n",
    "        \"\"\"\n",
    "        [b, h, w, c] = [int(dim) for dim in x.get_shape()]\n",
    "\n",
    "        return tf.image.resize_nearest_neighbor(x, (h_size, w_size))\n",
    "\n",
    "    def conv_layer(self, inputs, num_filters, filter_size, strides, activation=None,\n",
    "                   transpose=False, w_size=None, h_size=None):\n",
    "        \"\"\"\n",
    "        Add a convolutional layer to the network.\n",
    "        :param inputs: Inputs to the conv layer.\n",
    "        :param num_filters: Num of filters for conv layer.\n",
    "        :param filter_size: Size of filter.\n",
    "        :param strides: Stride size.\n",
    "        :param activation: Conv layer activation.\n",
    "        :param transpose: Whether to apply upscale before convolution.\n",
    "        :param w_size: Used only for upscale, w_size to scale to.\n",
    "        :param h_size: Used only for upscale, h_size to scale to.\n",
    "        :return: Convolution features\n",
    "        \"\"\"\n",
    "        self.conv_layer_num += 1\n",
    "        if transpose:\n",
    "            outputs = self.upscale(inputs, h_size=h_size, w_size=w_size)\n",
    "            outputs = tf.layers.conv2d_transpose(outputs, num_filters, filter_size,\n",
    "                                                 strides=strides,\n",
    "                                       padding=\"SAME\", activation=activation)\n",
    "        elif not transpose:\n",
    "            outputs = tf.layers.conv2d(inputs, num_filters, filter_size, strides=strides,\n",
    "                                                 padding=\"SAME\", activation=activation)\n",
    "        return outputs\n",
    "\n",
    "    def resize_batch(self, batch_images, size):\n",
    "\n",
    "        \"\"\"\n",
    "        Resize image batch using nearest neighbour\n",
    "        :param batch_images: Image batch\n",
    "        :param size: Size to upscale to\n",
    "        :return: Resized image batch.\n",
    "        \"\"\"\n",
    "        images = tf.image.resize_images(batch_images, size=size, method=ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "        return images\n",
    "\n",
    "    def add_encoder_layer(self, input, name, training, dropout_rate, layer_to_skip_connect, local_inner_layers,\n",
    "                          num_features, dim_reduce=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Adds a resnet encoder layer.\n",
    "        :param input: The input to the encoder layer\n",
    "        :param training: Flag for training or validation\n",
    "        :param dropout_rate: A float or a placeholder for the dropout rate\n",
    "        :param layer_to_skip_connect: Layer to skip-connect this layer to\n",
    "        :param local_inner_layers: A list with the inner layers of the current Multi-Layer\n",
    "        :param num_features: Number of feature maps for the convolutions\n",
    "        :param dim_reduce: Boolean value indicating if this is a dimensionality reducing layer or not\n",
    "        :return: The output of the encoder layer\n",
    "        \"\"\"\n",
    "        [b1, h1, w1, d1] = input.get_shape().as_list()\n",
    "\n",
    "        if len(layer_to_skip_connect) >= 2:\n",
    "            layer_to_skip_connect = layer_to_skip_connect[-2]\n",
    "        else:\n",
    "            layer_to_skip_connect = None\n",
    "        #print('layer_to_skip :', layer_to_skip_connect)\n",
    "\n",
    "        if layer_to_skip_connect is not None:\n",
    "            [b0, h0, w0, d0] = layer_to_skip_connect.get_shape().as_list()\n",
    "            if h0 > h1:\n",
    "                skip_connect_layer = self.conv_layer(layer_to_skip_connect, int(layer_to_skip_connect.get_shape()[3]),\n",
    "                                                     [3, 3], strides=(2, 2))\n",
    "            else:\n",
    "                skip_connect_layer = layer_to_skip_connect\n",
    "            current_layers = [input, skip_connect_layer]\n",
    "        else:\n",
    "            current_layers = [input]\n",
    "\n",
    "        current_layers.extend(local_inner_layers)\n",
    "        current_layers = remove_duplicates(current_layers)\n",
    "        #print('-----')\n",
    "        #print(current_layers)\n",
    "        outputs = tf.concat(current_layers, axis=3)\n",
    "        #print('------')\n",
    "        #print(outputs)        \n",
    "        #print('------')\n",
    "\n",
    "        if dim_reduce:\n",
    "            outputs = self.conv_layer(outputs, num_features, [3, 3], strides=(2, 2))\n",
    "            outputs = tf.nn.leaky_relu(outputs)\n",
    "            outputs = tf.contrib.layers.batch_norm(outputs, decay=0.99, scale=True,\n",
    "                                 center=True, is_training=training,\n",
    "                                 renorm=True)\n",
    "            outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=training)\n",
    "        else:\n",
    "            outputs = self.conv_layer(outputs, num_features, [3, 3], strides=(1, 1))\n",
    "            outputs = tf.nn.leaky_relu(features=outputs)\n",
    "            outputs = tf.contrib.layers.batch_norm(outputs, decay=0.99, scale=True,\n",
    "                                 center=True, is_training=training,\n",
    "                                 renorm=True)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def add_decoder_layer(self, input, name, training, dropout_rate, layer_to_skip_connect, local_inner_layers,\n",
    "                          num_features, dim_upscale=False, h_size=None, w_size=None):\n",
    "\n",
    "        \"\"\"\n",
    "        Adds a resnet decoder layer.\n",
    "        :param input: Input features\n",
    "        :param name: Layer Name\n",
    "        :param training: Training placeholder or boolean flag\n",
    "        :param dropout_rate: Float placeholder or float indicating the dropout rate\n",
    "        :param layer_to_skip_connect: Layer to skip connect to.\n",
    "        :param local_inner_layers: A list with the inner layers of the current MultiLayer\n",
    "        :param num_features: Num feature maps for convolution\n",
    "        :param dim_upscale: Dimensionality upscale\n",
    "        :param h_size: Height to upscale to\n",
    "        :param w_size: Width to upscale to\n",
    "        :return: The output of the decoder layer\n",
    "        \"\"\"\n",
    "        [b1, h1, w1, d1] = input.get_shape().as_list()\n",
    "        if len(layer_to_skip_connect) >= 2:\n",
    "            layer_to_skip_connect = layer_to_skip_connect[-2]\n",
    "        else:\n",
    "            layer_to_skip_connect = None\n",
    "\n",
    "        if layer_to_skip_connect is not None:\n",
    "            [b0, h0, w0, d0] = layer_to_skip_connect.get_shape().as_list()\n",
    "\n",
    "            if h0 < h1:\n",
    "                print('in if, layer_to_skip_connect : ', layer_to_skip_connect)\n",
    "                pp(layer_to_skip_connect)\n",
    "                skip_connect_layer = self.conv_layer(layer_to_skip_connect,\n",
    "                                                     int(layer_to_skip_connect.get_shape()[3]),\n",
    "                                                     [3, 3], strides=(1, 1),\n",
    "                                                     transpose=True,\n",
    "                                                     h_size=h_size,\n",
    "                                                     w_size=w_size)\n",
    "            else:\n",
    "                skip_connect_layer = layer_to_skip_connect\n",
    "            current_layers = [input, skip_connect_layer]\n",
    "        else:\n",
    "            current_layers = [input]\n",
    "        \n",
    "        current_layers.extend(local_inner_layers)\n",
    "        current_layers = remove_duplicates(current_layers)\n",
    "        print('****')\n",
    "        print('current_layers :', current_layers)\n",
    "        outputs = tf.concat(current_layers, axis=3)\n",
    "        print('****')\n",
    "        print('outputs : ', outputs)\n",
    "        print('****')\n",
    "\n",
    "\n",
    "        if dim_upscale:\n",
    "            print('in dim_up :', outputs)\n",
    "            outputs = self.conv_layer(outputs, num_features, [3, 3], strides=(1, 1),\n",
    "                                      transpose=True, w_size=w_size, h_size=h_size)\n",
    "            outputs = tf.nn.leaky_relu(features=outputs)\n",
    "            outputs = tf.contrib.layers.batch_norm(outputs,\n",
    "                                 decay=0.99, scale=True,\n",
    "                                 center=True, is_training=training,\n",
    "                                 renorm=True)\n",
    "            outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=training)\n",
    "            print('******')\n",
    "            print(outputs)\n",
    "        else:\n",
    "            outputs = self.conv_layer(outputs, num_features, [3, 3], strides=(1, 1),\n",
    "                                       transpose=False)\n",
    "            outputs = tf.nn.leaky_relu(features=outputs)\n",
    "            outputs = tf.contrib.layers.batch_norm(outputs, decay=0.99, scale=True,\n",
    "                                 center=True, is_training=training,\n",
    "                                 renorm=True)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def __call__(self, z_inputs, conditional_input, training=False, dropout_rate=0.0):\n",
    "        \"\"\"\n",
    "        Apply network on data.\n",
    "        :param z_inputs: Random noise to inject [batch_size, z_dim]\n",
    "        :param conditional_input: A batch of images to use as conditionals [batch_size, height, width, channels]\n",
    "        :param training: Training placeholder or boolean\n",
    "        :param dropout_rate: Dropout rate placeholder or float\n",
    "        :return: Returns x_g (generated images), encoder_layers(encoder features), decoder_layers(decoder features)\n",
    "        \"\"\"\n",
    "        conditional_input = tf.convert_to_tensor(conditional_input)\n",
    "        with tf.variable_scope(self.name, reuse=self.reuse):\n",
    "            # reshape from inputs\n",
    "            outputs = conditional_input\n",
    "            encoder_layers = []\n",
    "            current_layers = [outputs]\n",
    "            with tf.variable_scope('conv_layers'):\n",
    "\n",
    "                for i, layer_size in enumerate(self.layer_sizes):\n",
    "                    encoder_inner_layers = [outputs]\n",
    "                    with tf.variable_scope('g_conv{}'.format(i)):\n",
    "                        if i==0: #first layer is a single conv layer instead of MultiLayer for best results\n",
    "                            outputs = self.conv_layer(outputs, num_filters=64,\n",
    "                                                      filter_size=(3, 3), strides=(2, 2))\n",
    "                            outputs = tf.nn.leaky_relu(features=outputs)\n",
    "                            outputs = tf.contrib.layers.batch_norm(outputs, decay=0.99, scale=True,\n",
    "                                                 center=True, is_training=training,\n",
    "                                                 renorm=True)\n",
    "                            current_layers.append(outputs)\n",
    "                            encoder_inner_layers.append(outputs)\n",
    "                        else:\n",
    "                            for j in range(self.inner_layers[i]): #Build the inner Layers of the MultiLayer\n",
    "                                outputs = self.add_encoder_layer(input=outputs,\n",
    "                                                                 training=training,\n",
    "                                                                 name=\"encoder_layer_{}_{}\".format(i, j),\n",
    "                                                                 layer_to_skip_connect=current_layers,\n",
    "                                                                 num_features=self.layer_sizes[i],\n",
    "                                                                 dim_reduce=False,\n",
    "                                                                 local_inner_layers=encoder_inner_layers,\n",
    "                                                                 dropout_rate=dropout_rate)\n",
    "                                encoder_inner_layers.append(outputs)\n",
    "                                current_layers.append(outputs)\n",
    "                                #print('i :', i, 'j :', j, '_',current_layers)\n",
    "                            #add final dim reducing conv layer for this MultiLayer\n",
    "                            outputs = self.add_encoder_layer(input=outputs, name=\"encoder_layer_{}\".format(i),\n",
    "                                                             training=training, layer_to_skip_connect=current_layers,\n",
    "                                                             local_inner_layers=encoder_inner_layers,\n",
    "                                                             num_features=self.layer_sizes[i],\n",
    "                                                             dim_reduce=True, dropout_rate=dropout_rate)\n",
    "                            current_layers.append(outputs)\n",
    "                            #print('i :', i, 'j :', j, '_+_',current_layers)\n",
    "                        encoder_layers.append(outputs)\n",
    "\n",
    "            g_conv_encoder = outputs\n",
    "\n",
    "            with tf.variable_scope(\"vector_expansion\"):  # Used for expanding the z injected noise to match the\n",
    "                                                         # dimensionality of the various decoder MultiLayers, injecting\n",
    "                                                         # noise into multiple decoder layers in a skip-connection way\n",
    "                                                         # improves quality of results. We inject in the first 3 decode\n",
    "                                                         # multi layers\n",
    "                num_filters = 8\n",
    "                z_layers = []\n",
    "                concat_shape = [layer_shape.get_shape().as_list() for layer_shape in encoder_layers]\n",
    "                print('*****')\n",
    "                print('concat_shape :,', concat_shape)\n",
    "                print('*****')\n",
    "                print(self.inner_layers)\n",
    "                      \n",
    "                for i in range(len(self.inner_layers)):\n",
    "                    h = concat_shape[len(encoder_layers) - 1 - i][1]\n",
    "                    w = concat_shape[len(encoder_layers) - 1 - i][1]\n",
    "                    z_dense = tf.layers.dense(z_inputs, h * w * num_filters)\n",
    "                    z_reshape_noise = tf.reshape(z_dense, [self.batch_size, h, w, num_filters])\n",
    "                    num_filters /= 2\n",
    "                    num_filters = int(num_filters)\n",
    "                    print(z_reshape_noise)\n",
    "                    z_layers.append(z_reshape_noise)\n",
    "\n",
    "            outputs = g_conv_encoder\n",
    "            decoder_layers = []\n",
    "            current_layers = [outputs]\n",
    "            with tf.variable_scope('g_deconv_layers'):\n",
    "                for i in range(len(self.layer_sizes)+1):\n",
    "                    print('i :', i)\n",
    "                    if i<3: #Pass the injected noise to the first 3 decoder layers for sharper results\n",
    "                        outputs = tf.concat([z_layers[i], outputs], axis=3)\n",
    "                        current_layers[-1] = outputs\n",
    "                    idx = len(self.layer_sizes) - 1 - i\n",
    "                    num_features = self.layer_sizes[idx]\n",
    "                    inner_layers = self.inner_layers[idx]\n",
    "                    upscale_shape = encoder_layers[idx].get_shape().as_list()\n",
    "                    print('idx :', idx)\n",
    "                    if idx<0:\n",
    "                        num_features = self.layer_sizes[0]\n",
    "                        inner_layers = self.inner_layers[0]\n",
    "                        outputs = tf.concat([outputs, conditional_input], axis=3)\n",
    "                        upscale_shape = conditional_input.get_shape().as_list()\n",
    "\n",
    "                    with tf.variable_scope('g_deconv{}'.format(i)):\n",
    "                        decoder_inner_layers = [outputs]\n",
    "                        for j in range(inner_layers):\n",
    "                            print('j : ', j)\n",
    "                            if i==0 and j==0:\n",
    "                                print('first outputs :', outputs)\n",
    "                                print('******')\n",
    "                                outputs = self.add_decoder_layer(input=outputs,\n",
    "                                                                 name=\"decoder_inner_conv_{}_{}\"\n",
    "                                                                 .format(i, j),\n",
    "                                                                 training=training,\n",
    "                                                                 layer_to_skip_connect=current_layers,\n",
    "                                                                 num_features=num_features,\n",
    "                                                                 dim_upscale=False,\n",
    "                                                                 local_inner_layers=decoder_inner_layers,\n",
    "                                                                 dropout_rate=dropout_rate)\n",
    "                                decoder_inner_layers.append(outputs)\n",
    "                            else:\n",
    "                                outputs = self.add_decoder_layer(input=outputs,\n",
    "                                                                 name=\"decoder_inner_conv_{}_{}\"\n",
    "                                                                 .format(i, j), training=training,\n",
    "                                                                 layer_to_skip_connect=current_layers,\n",
    "                                                                 num_features=num_features,\n",
    "                                                                 dim_upscale=False,\n",
    "                                                                 local_inner_layers=decoder_inner_layers,\n",
    "                                                                 w_size=upscale_shape[1],\n",
    "                                                                 h_size=upscale_shape[2],\n",
    "                                                                 dropout_rate=dropout_rate)\n",
    "                                decoder_inner_layers.append(outputs)\n",
    "                        current_layers.append(outputs)\n",
    "                        decoder_layers.append(outputs)\n",
    "\n",
    "                        if idx>=0:\n",
    "                            upscale_shape = encoder_layers[idx - 1].get_shape().as_list()\n",
    "                            if idx == 0:\n",
    "                                upscale_shape = conditional_input.get_shape().as_list()\n",
    "                            outputs = self.add_decoder_layer(\n",
    "                                input=outputs,\n",
    "                                name=\"decoder_outer_conv_{}\".format(i),\n",
    "                                training=training,\n",
    "                                layer_to_skip_connect=current_layers,\n",
    "                                num_features=num_features,\n",
    "                                dim_upscale=True, local_inner_layers=decoder_inner_layers, w_size=upscale_shape[1],\n",
    "                                h_size=upscale_shape[2], dropout_rate=dropout_rate)\n",
    "                            current_layers.append(outputs)\n",
    "                        if (idx-1)>=0:\n",
    "                            outputs = tf.concat([outputs, encoder_layers[idx-1]], axis=3)\n",
    "                            current_layers[-1] = outputs\n",
    "\n",
    "                high_res_layers = []\n",
    "\n",
    "                for p in range(2):\n",
    "                    outputs = self.conv_layer(outputs, self.layer_sizes[0], [3, 3], strides=(1, 1),\n",
    "                                                         transpose=False)\n",
    "                    print('p_outputs : ', outputs)\n",
    "                    outputs = tf.nn.leaky_relu(features=outputs)\n",
    "\n",
    "                    outputs = tf.contrib.layers.batch_norm(outputs,\n",
    "                                         decay=0.99, scale=True,\n",
    "                                         center=True, is_training=training,\n",
    "                                         renorm=True)\n",
    "                    high_res_layers.append(outputs)\n",
    "                outputs = self.conv_layer(outputs, self.num_channels, [3, 3], strides=(1, 1),\n",
    "                                                     transpose=False)\n",
    "            # output images\n",
    "            with tf.variable_scope('g_tanh'):\n",
    "                gan_decoder = tf.tanh(outputs, name='outputs')\n",
    "\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)\n",
    "\n",
    "        if self.build:\n",
    "            print(\"generator_total_layers\", self.conv_layer_num)\n",
    "            count_parameters(self.variables, name=\"generator_parameter_num\")\n",
    "        self.build = False\n",
    "        return gan_decoder, encoder_layers, decoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = UResNetGenerator([64, 64, 64, 64], [\"SAME\", \"SAME\", \"SAME\", \"SAME\"], 16, 3, [3,3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "concat_shape :, [[16, 14, 14, 64], [16, 7, 7, 64], [16, 4, 4, 64], [16, 2, 2, 64]]\n",
      "*****\n",
      "[3, 3, 3, 3]\n",
      "Tensor(\"g/vector_expansion/Reshape:0\", shape=(16, 2, 2, 8), dtype=float32)\n",
      "Tensor(\"g/vector_expansion/Reshape_1:0\", shape=(16, 4, 4, 4), dtype=float32)\n",
      "Tensor(\"g/vector_expansion/Reshape_2:0\", shape=(16, 7, 7, 2), dtype=float32)\n",
      "Tensor(\"g/vector_expansion/Reshape_3:0\", shape=(16, 14, 14, 1), dtype=float32)\n",
      "i : 0\n",
      "idx : 3\n",
      "j :  0\n",
      "first outputs : Tensor(\"g/g_deconv_layers/concat:0\", shape=(16, 2, 2, 72), dtype=float32)\n",
      "******\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/concat:0' shape=(16, 2, 2, 72) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv0/concat:0\", shape=(16, 2, 2, 72), dtype=float32)\n",
      "****\n",
      "j :  1\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv0/BatchNorm/batchnorm_1/add_1:0' shape=(16, 2, 2, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat:0' shape=(16, 2, 2, 72) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv0/concat_1:0\", shape=(16, 2, 2, 136), dtype=float32)\n",
      "****\n",
      "j :  2\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv0/BatchNorm_1/batchnorm/add_1:0' shape=(16, 2, 2, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat:0' shape=(16, 2, 2, 72) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv0/BatchNorm/batchnorm_1/add_1:0' shape=(16, 2, 2, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv0/concat_2:0\", shape=(16, 2, 2, 200), dtype=float32)\n",
      "****\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0' shape=(16, 2, 2, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat:0' shape=(16, 2, 2, 72) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv0/BatchNorm/batchnorm_1/add_1:0' shape=(16, 2, 2, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv0/BatchNorm_1/batchnorm/add_1:0' shape=(16, 2, 2, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv0/concat_3:0\", shape=(16, 2, 2, 264), dtype=float32)\n",
      "****\n",
      "in dim_up : Tensor(\"g/g_deconv_layers/g_deconv0/concat_3:0\", shape=(16, 2, 2, 264), dtype=float32)\n",
      "******\n",
      "Tensor(\"g/g_deconv_layers/g_deconv0/dropout/Identity:0\", shape=(16, 4, 4, 64), dtype=float32)\n",
      "i : 1\n",
      "idx : 2\n",
      "j :  0\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 2, 2, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/concat_1:0' shape=(16, 4, 4, 132) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv1/conv2d_transpose/BiasAdd:0' shape=(16, 4, 4, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv1/concat:0\", shape=(16, 4, 4, 196), dtype=float32)\n",
      "****\n",
      "j :  1\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 2, 2, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv1/BatchNorm/batchnorm_1/add_1:0' shape=(16, 4, 4, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv1/conv2d_transpose_1/BiasAdd:0' shape=(16, 4, 4, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat_1:0' shape=(16, 4, 4, 132) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv1/concat_1:0\", shape=(16, 4, 4, 260), dtype=float32)\n",
      "****\n",
      "j :  2\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 2, 2, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv1/BatchNorm_1/batchnorm/add_1:0' shape=(16, 4, 4, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv1/conv2d_transpose_2/BiasAdd:0' shape=(16, 4, 4, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat_1:0' shape=(16, 4, 4, 132) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv1/BatchNorm/batchnorm_1/add_1:0' shape=(16, 4, 4, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv1/concat_2:0\", shape=(16, 4, 4, 324), dtype=float32)\n",
      "****\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0' shape=(16, 4, 4, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat_1:0' shape=(16, 4, 4, 132) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv1/BatchNorm/batchnorm_1/add_1:0' shape=(16, 4, 4, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv1/BatchNorm_1/batchnorm/add_1:0' shape=(16, 4, 4, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv1/concat_3:0\", shape=(16, 4, 4, 324), dtype=float32)\n",
      "****\n",
      "in dim_up : Tensor(\"g/g_deconv_layers/g_deconv1/concat_3:0\", shape=(16, 4, 4, 324), dtype=float32)\n",
      "******\n",
      "Tensor(\"g/g_deconv_layers/g_deconv1/dropout/Identity:0\", shape=(16, 7, 7, 64), dtype=float32)\n",
      "i : 2\n",
      "idx : 1\n",
      "j :  0\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 4, 4, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/concat_2:0' shape=(16, 7, 7, 130) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv2/conv2d_transpose/BiasAdd:0' shape=(16, 7, 7, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv2/concat:0\", shape=(16, 7, 7, 194), dtype=float32)\n",
      "****\n",
      "j :  1\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 4, 4, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv2/BatchNorm/batchnorm_1/add_1:0' shape=(16, 7, 7, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv2/conv2d_transpose_1/BiasAdd:0' shape=(16, 7, 7, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat_2:0' shape=(16, 7, 7, 130) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv2/concat_1:0\", shape=(16, 7, 7, 258), dtype=float32)\n",
      "****\n",
      "j :  2\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 4, 4, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv2/BatchNorm_1/batchnorm/add_1:0' shape=(16, 7, 7, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv2/conv2d_transpose_2/BiasAdd:0' shape=(16, 7, 7, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat_2:0' shape=(16, 7, 7, 130) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv2/BatchNorm/batchnorm_1/add_1:0' shape=(16, 7, 7, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv2/concat_2:0\", shape=(16, 7, 7, 322), dtype=float32)\n",
      "****\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0' shape=(16, 7, 7, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat_2:0' shape=(16, 7, 7, 130) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv2/BatchNorm/batchnorm_1/add_1:0' shape=(16, 7, 7, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv2/BatchNorm_1/batchnorm/add_1:0' shape=(16, 7, 7, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv2/concat_3:0\", shape=(16, 7, 7, 322), dtype=float32)\n",
      "****\n",
      "in dim_up : Tensor(\"g/g_deconv_layers/g_deconv2/concat_3:0\", shape=(16, 7, 7, 322), dtype=float32)\n",
      "******\n",
      "Tensor(\"g/g_deconv_layers/g_deconv2/dropout/Identity:0\", shape=(16, 14, 14, 64), dtype=float32)\n",
      "i : 3\n",
      "idx : 0\n",
      "j :  0\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 7, 7, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv2/concat_4:0' shape=(16, 14, 14, 128) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv3/conv2d_transpose/BiasAdd:0' shape=(16, 14, 14, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv3/concat:0\", shape=(16, 14, 14, 192), dtype=float32)\n",
      "****\n",
      "j :  1\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 7, 7, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv3/BatchNorm/batchnorm_1/add_1:0' shape=(16, 14, 14, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv3/conv2d_transpose_1/BiasAdd:0' shape=(16, 14, 14, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv2/concat_4:0' shape=(16, 14, 14, 128) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv3/concat_1:0\", shape=(16, 14, 14, 256), dtype=float32)\n",
      "****\n",
      "j :  2\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 7, 7, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv3/BatchNorm_1/batchnorm/add_1:0' shape=(16, 14, 14, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv3/conv2d_transpose_2/BiasAdd:0' shape=(16, 14, 14, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv2/concat_4:0' shape=(16, 14, 14, 128) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv3/BatchNorm/batchnorm_1/add_1:0' shape=(16, 14, 14, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv3/concat_2:0\", shape=(16, 14, 14, 320), dtype=float32)\n",
      "****\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0' shape=(16, 14, 14, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv2/concat_4:0' shape=(16, 14, 14, 128) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv3/BatchNorm/batchnorm_1/add_1:0' shape=(16, 14, 14, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv3/BatchNorm_1/batchnorm/add_1:0' shape=(16, 14, 14, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv3/concat_3:0\", shape=(16, 14, 14, 320), dtype=float32)\n",
      "****\n",
      "in dim_up : Tensor(\"g/g_deconv_layers/g_deconv3/concat_3:0\", shape=(16, 14, 14, 320), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "Tensor(\"g/g_deconv_layers/g_deconv3/dropout/Identity:0\", shape=(16, 28, 28, 64), dtype=float32)\n",
      "i : 4\n",
      "idx : -1\n",
      "j :  0\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 14, 14, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/concat_3:0' shape=(16, 28, 28, 67) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv4/conv2d_transpose/BiasAdd:0' shape=(16, 28, 28, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv4/concat:0\", shape=(16, 28, 28, 131), dtype=float32)\n",
      "****\n",
      "j :  1\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 14, 14, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv4/BatchNorm/batchnorm_1/add_1:0' shape=(16, 28, 28, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv4/conv2d_transpose_1/BiasAdd:0' shape=(16, 28, 28, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat_3:0' shape=(16, 28, 28, 67) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv4/concat_1:0\", shape=(16, 28, 28, 195), dtype=float32)\n",
      "****\n",
      "j :  2\n",
      "in if, layer_to_skip_connect :  Tensor(\"g/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0\", shape=(16, 14, 14, 64), dtype=float32)\n",
      "****\n",
      "current_layers : [<tf.Tensor 'g/g_deconv_layers/g_deconv4/BatchNorm_1/batchnorm/add_1:0' shape=(16, 28, 28, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv4/conv2d_transpose_2/BiasAdd:0' shape=(16, 28, 28, 64) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/concat_3:0' shape=(16, 28, 28, 67) dtype=float32>, <tf.Tensor 'g/g_deconv_layers/g_deconv4/BatchNorm/batchnorm_1/add_1:0' shape=(16, 28, 28, 64) dtype=float32>]\n",
      "****\n",
      "outputs :  Tensor(\"g/g_deconv_layers/g_deconv4/concat_2:0\", shape=(16, 28, 28, 259), dtype=float32)\n",
      "****\n",
      "p_outputs :  Tensor(\"g/g_deconv_layers/conv2d/BiasAdd:0\", shape=(16, 28, 28, 64), dtype=float32)\n",
      "p_outputs :  Tensor(\"g/g_deconv_layers/conv2d_1/BiasAdd:0\", shape=(16, 28, 28, 64), dtype=float32)\n",
      "generator_total_layers 50\n",
      "generator_parameter_num 4439477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'g/g_tanh/outputs:0' shape=(16, 28, 28, 3) dtype=float32>,\n",
       " [<tf.Tensor 'g/conv_layers/g_conv0/BatchNorm/batchnorm_1/add_1:0' shape=(16, 14, 14, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/conv_layers/g_conv1/dropout/Identity:0' shape=(16, 7, 7, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/conv_layers/g_conv2/dropout/Identity:0' shape=(16, 4, 4, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/conv_layers/g_conv3/dropout/Identity:0' shape=(16, 2, 2, 64) dtype=float32>],\n",
       " [<tf.Tensor 'g/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0' shape=(16, 2, 2, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0' shape=(16, 4, 4, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0' shape=(16, 7, 7, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0' shape=(16, 14, 14, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/g_deconv_layers/g_deconv4/BatchNorm_2/batchnorm/add_1:0' shape=(16, 28, 28, 64) dtype=float32>])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(z_input, x, training=False, dropout_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
