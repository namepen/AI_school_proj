{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2591)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros(shape=[1200,10,28,28,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.choice(z.shape[0], 16, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.choice(len(z[0]), 10, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = z[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10, 28, 28, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = x_2[:, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = np.reshape(x_gen, newshape=(x_gen.shape[0] * x_gen.shape[1],\n",
    "                                                      x_gen.shape[2], x_gen.shape[3], x_gen.shape[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 28, 28, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_batch(self, dataset_name):\n",
    "        \"\"\"\n",
    "        Generates a data batch to be used for training or evaluation\n",
    "        :param set_name: The name of the set to use, e.g. \"train\", \"val\" etc\n",
    "        :return: A data batch\n",
    "        \"\"\"\n",
    "        choose_classes = np.random.choice(len(self.datasets[dataset_name]), size=self.batch_size)\n",
    "        choose_samples = np.random.choice(self.datasets[dataset_name].shape[1], size=2 * self.batch_size,\n",
    "                                          replace=True)\n",
    "\n",
    "        choose_samples_a = choose_samples[:self.batch_size]\n",
    "        choose_samples_b = choose_samples[self.batch_size:]\n",
    "\n",
    "        x_input_batch_a = []\n",
    "        x_input_batch_b = []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            x_input_batch_a.append(self.datasets[dataset_name][choose_classes[i], choose_samples_a[i]])\n",
    "            x_input_batch_b.append(self.datasets[dataset_name][choose_classes[i], choose_samples_b[i]])\n",
    "\n",
    "        x_input_batch_a = np.array(x_input_batch_a)\n",
    "        x_input_batch_b = np.array(x_input_batch_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAGANDataset(object):\n",
    "    def __init__(self, batch_size, last_training_class_index, reverse_channels, num_of_gpus, gen_batches):\n",
    "        \"\"\"\n",
    "        :param batch_size: The batch size to use for the data loader\n",
    "        :param last_training_class_index: The final index for the training set, used to restrict the training set\n",
    "        if needed. E.g. if training set is 1200 classes and last_training_class_index=900 then only the first 900\n",
    "        classes will be used\n",
    "        :param reverse_channels: A boolean indicating whether we need to reverse the colour channels e.g. RGB to BGR\n",
    "        :param num_of_gpus: Number of gpus to use for training\n",
    "        :param gen_batches: How many batches to use from the validation set for the end of epoch generations\n",
    "        \"\"\"\n",
    "        self.x_train, self.x_test, self.x_val = self.load_dataset(last_training_class_index) #x_train = [1200, 10, 28, 28, 3]\n",
    "        self.num_of_gpus = num_of_gpus\n",
    "        self.batch_size = batch_size\n",
    "        self.reverse_channels = reverse_channels\n",
    "        self.test_samples_per_label = gen_batches\n",
    "        self.choose_gen_labels = np.random.choice(self.x_val.shape[0], self.batch_size, replace=True)\n",
    "        self.choose_gen_samples = np.random.choice(len(self.x_val[0]), self.test_samples_per_label, replace=True)\n",
    "        self.x_gen = self.x_val[self.choose_gen_labels]\n",
    "        self.x_gen = self.x_gen[:, self.choose_gen_samples]\n",
    "        self.x_gen = np.reshape(self.x_gen, newshape=(self.x_gen.shape[0] * self.x_gen.shape[1],\n",
    "                                                      self.x_gen.shape[2], self.x_gen.shape[3], self.x_gen.shape[4]))\n",
    "        self.gen_batches = gen_batches\n",
    "\n",
    "        self.train_index = 0\n",
    "        self.val_index = 0\n",
    "        self.test_index = 0\n",
    "\n",
    "        self.indexes = {\"train\": 0, \"val\": 0, \"test\": 0, \"gen\": 0}\n",
    "        self.datasets = {\"train\": self.x_train, \"gen\": self.x_gen,\n",
    "                         \"val\": self.x_val,\n",
    "                         \"test\": self.x_test}\n",
    "\n",
    "        self.image_height = self.x_train.shape[2]\n",
    "        self.image_width = self.x_train.shape[3]\n",
    "        self.image_channel = self.x_train.shape[4]\n",
    "        self.training_data_size = self.x_train.shape[0] * self.x_train.shape[1]\n",
    "        self.validation_data_size = gen_batches * self.batch_size\n",
    "        self.testing_data_size = self.x_test.shape[0] * self.x_test.shape[1]\n",
    "        self.generation_data_size = self.gen_batches * self.batch_size\n",
    "\n",
    "    def load_dataset(self, last_training_class_index):\n",
    "        \"\"\"\n",
    "        Loads the dataset into the data loader class. To be implemented in all classes that inherit\n",
    "        DAGANImbalancedDataset\n",
    "        :param last_training_class_index: last_training_class_index: The final index for the training set,\n",
    "        used to restrict the training set if needed. E.g. if training set is 1200 classes and\n",
    "        last_training_class_index=900 then only the first 900 classes will be used\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def preprocess_data(self, x):\n",
    "        \"\"\"\n",
    "        Preprocesses data such that their values lie in the -1.0 to 1.0 range so that the tanh activation gen output\n",
    "        can work properly\n",
    "        :param x: A data batch to preprocess\n",
    "        :return: A preprocessed data batch\n",
    "        \"\"\"\n",
    "        x = 2 * x - 1\n",
    "        if self.reverse_channels:\n",
    "            reverse_photos = np.ones(shape=x.shape)\n",
    "            for channel in range(x.shape[-1]):\n",
    "                reverse_photos[:, :, :, x.shape[-1] - 1 - channel] = x[:, :, :, channel]\n",
    "            x = reverse_photos\n",
    "        return x\n",
    "\n",
    "    def reconstruct_original(self, x):\n",
    "        \"\"\"\n",
    "        Applies the reverse operations that preprocess_data() applies such that the data returns to their original form\n",
    "        :param x: A batch of data to reconstruct\n",
    "        :return: A reconstructed batch of data\n",
    "        \"\"\"\n",
    "        x = (x + 1) / 2\n",
    "        return x\n",
    "\n",
    "    def shuffle(self, x):\n",
    "        \"\"\"\n",
    "        Shuffles the data batch along it's first axis\n",
    "        :param x: A data batch\n",
    "        :return: A shuffled data batch\n",
    "        \"\"\"\n",
    "        indices = np.arange(len(x))\n",
    "        np.random.shuffle(indices)\n",
    "        x = x[indices]\n",
    "        return x\n",
    "\n",
    "    def get_batch(self, dataset_name):\n",
    "        \"\"\"\n",
    "        Generates a data batch to be used for training or evaluation\n",
    "        :param set_name: The name of the set to use, e.g. \"train\", \"val\" etc\n",
    "        :return: A data batch\n",
    "        \"\"\"\n",
    "        choose_classes = np.random.choice(len(self.datasets[dataset_name]), size=self.batch_size)\n",
    "        choose_samples = np.random.choice(self.datasets[dataset_name].shape[1], size=2 * self.batch_size,\n",
    "                                          replace=True)\n",
    "\n",
    "        choose_samples_a = choose_samples[:self.batch_size]\n",
    "        choose_samples_b = choose_samples[self.batch_size:]\n",
    "\n",
    "        x_input_batch_a = []\n",
    "        x_input_batch_b = []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            x_input_batch_a.append(self.datasets[dataset_name][choose_classes[i], choose_samples_a[i]])\n",
    "            x_input_batch_b.append(self.datasets[dataset_name][choose_classes[i], choose_samples_b[i]])\n",
    "\n",
    "        x_input_batch_a = np.array(x_input_batch_a)\n",
    "        x_input_batch_b = np.array(x_input_batch_b)\n",
    "\n",
    "        return self.preprocess_data(x_input_batch_a), self.preprocess_data(x_input_batch_b)\n",
    "\n",
    "    def get_next_gen_batch(self):\n",
    "        \"\"\"\n",
    "        Provides a batch that contains data to be used for generation\n",
    "        :return: A data batch to use for generation\n",
    "        \"\"\"\n",
    "        if self.indexes[\"gen\"] >= self.batch_size * self.gen_batches:\n",
    "            self.indexes[\"gen\"] = 0\n",
    "        x_input_batch_a = self.datasets[\"gen\"][self.indexes[\"gen\"]:self.indexes[\"gen\"]+self.batch_size]\n",
    "        self.indexes[\"gen\"] += self.batch_size\n",
    "        return self.preprocess_data(x_input_batch_a)\n",
    "\n",
    "    def get_multi_batch(self, dataset_name):\n",
    "        \"\"\"\n",
    "        Returns a batch to be used for training or evaluation for multi gpu training\n",
    "        :param set_name: The name of the data-set to use e.g. \"train\", \"test\" etc\n",
    "        :return: Two batches (i.e. x_i and x_j) of size [num_gpus, batch_size, im_height, im_width, im_channels). If\n",
    "        the set is \"gen\" then we only return a single batch (i.e. x_i)\n",
    "        \"\"\"\n",
    "        x_input_a_batch = []\n",
    "        x_input_b_batch = []\n",
    "        if dataset_name == \"gen\":\n",
    "            x_input_a = self.get_next_gen_batch()\n",
    "            for n_batch in range(self.num_of_gpus):\n",
    "                x_input_a_batch.append(x_input_a)\n",
    "            x_input_a_batch = np.array(x_input_a_batch)\n",
    "            return x_input_a_batch\n",
    "        else:\n",
    "            for n_batch in range(self.num_of_gpus):\n",
    "                x_input_a, x_input_b = self.get_batch(dataset_name)\n",
    "                x_input_a_batch.append(x_input_a)\n",
    "                x_input_b_batch.append(x_input_b)\n",
    "\n",
    "            x_input_a_batch = np.array(x_input_a_batch)\n",
    "            x_input_b_batch = np.array(x_input_b_batch)\n",
    "\n",
    "            return x_input_a_batch, x_input_b_batch\n",
    "\n",
    "    def get_train_batch(self):\n",
    "        \"\"\"\n",
    "        Provides a training batch\n",
    "        :return: Returns a tuple of two data batches (i.e. x_i and x_j) to be used for training\n",
    "        \"\"\"\n",
    "        x_input_a, x_input_b = self.get_multi_batch(\"train\")\n",
    "        return x_input_a, x_input_b\n",
    "\n",
    "    def get_test_batch(self):\n",
    "        \"\"\"\n",
    "        Provides a test batch\n",
    "        :return: Returns a tuple of two data batches (i.e. x_i and x_j) to be used for evaluation\n",
    "        \"\"\"\n",
    "        x_input_a, x_input_b = self.get_multi_batch(\"test\")\n",
    "        return x_input_a, x_input_b\n",
    "\n",
    "    def get_val_batch(self):\n",
    "        \"\"\"\n",
    "        Provides a val batch\n",
    "        :return: Returns a tuple of two data batches (i.e. x_i and x_j) to be used for evaluation\n",
    "        \"\"\"\n",
    "        x_input_a, x_input_b = self.get_multi_batch(\"val\")\n",
    "        return x_input_a, x_input_b\n",
    "\n",
    "    def get_gen_batch(self):\n",
    "        \"\"\"\n",
    "        Provides a gen batch\n",
    "        :return: Returns a single data batch (i.e. x_i) to be used for generation on unseen data\n",
    "        \"\"\"\n",
    "        x_input_a = self.get_multi_batch(\"gen\")\n",
    "        return x_input_a\n",
    "\n",
    "class DAGANImbalancedDataset(DAGANDataset):\n",
    "    def __init__(self, batch_size, last_training_class_index, reverse_channels, num_of_gpus, gen_batches):\n",
    "        \"\"\"\n",
    "                :param batch_size: The batch size to use for the data loader\n",
    "                :param last_training_class_index: The final index for the training set, used to restrict the training set\n",
    "                if needed. E.g. if training set is 1200 classes and last_training_class_index=900 then only the first 900\n",
    "                classes will be used\n",
    "                :param reverse_channels: A boolean indicating whether we need to reverse the colour channels e.g. RGB to BGR\n",
    "                :param num_of_gpus: Number of gpus to use for training\n",
    "                :param gen_batches: How many batches to use from the validation set for the end of epoch generations\n",
    "                \"\"\"\n",
    "        self.x_train, self.x_test, self.x_val = self.load_dataset(last_training_class_index)\n",
    "\n",
    "        self.training_data_size = np.sum([len(self.x_train[i]) for i in range(self.x_train.shape[0])])\n",
    "        self.validation_data_size = np.sum([len(self.x_val[i]) for i in range(self.x_val.shape[0])])\n",
    "        self.testing_data_size = np.sum([len(self.x_test[i]) for i in range(self.x_test.shape[0])])\n",
    "        self.generation_data_size = gen_batches * batch_size\n",
    "\n",
    "        self.num_of_gpus = num_of_gpus\n",
    "        self.batch_size = batch_size\n",
    "        self.reverse_channels = reverse_channels\n",
    "\n",
    "        val_dict = dict()\n",
    "        idx = 0\n",
    "        for i in range(self.x_val.shape[0]):\n",
    "            temp = self.x_val[i]\n",
    "            for j in range(len(temp)):\n",
    "                val_dict[idx] = {\"sample_idx\": j, \"label_idx\": i}\n",
    "                idx += 1\n",
    "        choose_gen_samples = np.random.choice([i for i in range(self.validation_data_size)],\n",
    "                                                   size=self.generation_data_size)\n",
    "\n",
    "\n",
    "        self.x_gen = np.array([self.x_val[val_dict[idx][\"label_idx\"]][val_dict[idx][\"sample_idx\"]]\n",
    "                               for idx in choose_gen_samples])\n",
    "\n",
    "        self.train_index = 0\n",
    "        self.val_index = 0\n",
    "        self.test_index = 0\n",
    "\n",
    "        self.indexes = {\"train\": 0, \"val\": 0, \"test\": 0, \"gen\": 0}\n",
    "        self.datasets = {\"train\": self.x_train, \"gen\": self.x_gen,\n",
    "                         \"val\": self.x_val,\n",
    "                         \"test\": self.x_test}\n",
    "\n",
    "        self.gen_data_size = gen_batches * self.batch_size\n",
    "        self.image_height = self.x_train[0][0].shape[0]\n",
    "        self.image_width = self.x_train[0][0].shape[1]\n",
    "        self.image_channel = self.x_train[0][0].shape[2]\n",
    "\n",
    "    def get_batch(self, set_name):\n",
    "        \"\"\"\n",
    "        Generates a data batch to be used for training or evaluation\n",
    "        :param set_name: The name of the set to use, e.g. \"train\", \"val\" etc\n",
    "        :return: A data batch\n",
    "        \"\"\"\n",
    "        choose_classes = np.random.choice(len(self.datasets[set_name]), size=self.batch_size)\n",
    "\n",
    "        x_input_batch_a = []\n",
    "        x_input_batch_b = []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            choose_samples = np.random.choice(len(self.datasets[set_name][choose_classes[i]]),\n",
    "                                              size=2 * self.batch_size,\n",
    "                                              replace=True)\n",
    "\n",
    "            choose_samples_a = choose_samples[:self.batch_size]\n",
    "            choose_samples_b = choose_samples[self.batch_size:]\n",
    "            current_class_samples = self.datasets[set_name][choose_classes[i]]\n",
    "            x_input_batch_a.append(current_class_samples[choose_samples_a[i]])\n",
    "            x_input_batch_b.append(current_class_samples[choose_samples_b[i]])\n",
    "\n",
    "        x_input_batch_a = np.array(x_input_batch_a)\n",
    "        x_input_batch_b = np.array(x_input_batch_b)\n",
    "\n",
    "        return self.preprocess_data(x_input_batch_a), self.preprocess_data(x_input_batch_b)\n",
    "\n",
    "    def get_next_gen_batch(self):\n",
    "        \"\"\"\n",
    "        Provides a batch that contains data to be used for generation\n",
    "        :return: A data batch to use for generation\n",
    "        \"\"\"\n",
    "        if self.indexes[\"gen\"] >= self.gen_data_size:\n",
    "            self.indexes[\"gen\"] = 0\n",
    "        x_input_batch_a = self.datasets[\"gen\"][self.indexes[\"gen\"]:self.indexes[\"gen\"]+self.batch_size]\n",
    "        self.indexes[\"gen\"] += self.batch_size\n",
    "        return self.preprocess_data(x_input_batch_a)\n",
    "\n",
    "    def get_multi_batch(self, set_name):\n",
    "        \"\"\"\n",
    "        Returns a batch to be used for training or evaluation for multi gpu training\n",
    "        :param set_name: The name of the data-set to use e.g. \"train\", \"test\" etc\n",
    "        :return: Two batches (i.e. x_i and x_j) of size [num_gpus, batch_size, im_height, im_width, im_channels). If\n",
    "        the set is \"gen\" then we only return a single batch (i.e. x_i)\n",
    "        \"\"\"\n",
    "        x_input_a_batch = []\n",
    "        x_input_b_batch = []\n",
    "        if set_name == \"gen\":\n",
    "            x_input_a = self.get_next_gen_batch()\n",
    "            for n_batch in range(self.num_of_gpus):\n",
    "                x_input_a_batch.append(x_input_a)\n",
    "            x_input_a_batch = np.array(x_input_a_batch)\n",
    "            return x_input_a_batch\n",
    "        else:\n",
    "            for n_batch in range(self.num_of_gpus):\n",
    "                x_input_a, x_input_b = self.get_batch(set_name)\n",
    "                x_input_a_batch.append(x_input_a)\n",
    "                x_input_b_batch.append(x_input_b)\n",
    "\n",
    "            x_input_a_batch = np.array(x_input_a_batch)\n",
    "            x_input_b_batch = np.array(x_input_b_batch)\n",
    "\n",
    "            return x_input_a_batch, x_input_b_batch\n",
    "\n",
    "\n",
    "class OmniglotDAGANDataset(DAGANDataset):\n",
    "    def __init__(self, batch_size, last_training_class_index, reverse_channels, num_of_gpus, gen_batches):\n",
    "        super(OmniglotDAGANDataset, self).__init__(batch_size, last_training_class_index, reverse_channels, num_of_gpus,\n",
    "                                                   gen_batches)\n",
    "\n",
    "    def load_dataset(self, gan_training_index):\n",
    "        self.x = np.load(\"datasets/omniglot_data.npy\")\n",
    "        self.x = self.x / np.max(self.x)\n",
    "        x_train, x_test, x_val = self.x[:], self.x[:], self.x[:]\n",
    "        x_train = x_train[:gan_training_index]\n",
    "        return x_train, x_test, x_val\n",
    "\n",
    "class OmniglotImbalancedDAGANDataset(DAGANImbalancedDataset):\n",
    "    def __init__(self, batch_size, last_training_class_index, reverse_channels, num_of_gpus, gen_batches):\n",
    "        super(OmniglotImbalancedDAGANDataset, self).__init__(batch_size, last_training_class_index, reverse_channels,\n",
    "                                                             num_of_gpus, gen_batches)\n",
    "    def load_dataset(self, last_training_class_index):\n",
    "        x = np.load(\"datasets/omniglot_data.npy\")\n",
    "        #x_temp = []\n",
    "        #for i in range(x.shape[0]):\n",
    "        #    choose_samples = np.random.choice([i for i in range(1, 15)])\n",
    "        #    x_temp.append(x[i, :choose_samples])\n",
    "        #self.x = np.array(x_temp)\n",
    "        self.x = self.x / np.max(self.x)\n",
    "        x_train, x_test, x_val = self.x[:], self.x[:], self.x[:]\n",
    "        x_train = x_train[:last_training_class_index]\n",
    "\n",
    "        return x_train, x_test, x_val\n",
    "\n",
    "\n",
    "class VGGFaceDAGANDataset(DAGANDataset):\n",
    "    def __init__(self, batch_size, last_training_class_index, reverse_channels, num_of_gpus, gen_batches):\n",
    "        super(VGGFaceDAGANDataset, self).__init__(batch_size, last_training_class_index, reverse_channels, num_of_gpus,\n",
    "                                                  gen_batches)\n",
    "\n",
    "    def load_dataset(self, gan_training_index):\n",
    "\n",
    "        self.x = np.load(\"datasets/vgg_face_data.npy\")\n",
    "        self.x = self.x / np.max(self.x)\n",
    "        self.x = np.reshape(self.x, newshape=(2354, 100, 64, 64, 3))\n",
    "        x_train, x_test, x_val = self.x[:1803], self.x[1803:2300], self.x[2300:]\n",
    "        x_train = x_train[:gan_training_index]\n",
    "\n",
    "        return x_train, x_test, x_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OmniglotDAGANDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fb4228694bc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDAGANDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m900\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-15c75cf4dd34>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_size, last_training_class_index, reverse_channels, num_of_gpus, gen_batches)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mHow\u001b[0m \u001b[0mmany\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mset\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mend\u001b[0m \u001b[0mof\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0mgenerations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \"\"\"\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_training_class_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_of_gpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_of_gpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-15c75cf4dd34>\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(self, last_training_class_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mlast_training_class_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m900\u001b[0m \u001b[0mthen\u001b[0m \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfirst\u001b[0m \u001b[1;36m900\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \"\"\"\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = DAGANDataset(16, 900, True, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-dc24e866710b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m dataset.OmniglotDAGANDataset(batch_size=batch_size, last_training_class_index=1, reverse_channels=True,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                     num_of_gpus=num_gpus, gen_batches=10)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset.OmniglotDAGANDataset(batch_size=batch_size, last_training_class_index=1, reverse_channels=True,\n",
    "                                    num_of_gpus=num_gpus, gen_batches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
