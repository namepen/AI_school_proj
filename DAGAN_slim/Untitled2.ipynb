{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(network_variables, name):\n",
    "    \"\"\"\n",
    "    This method counts the tota\n",
    "    l number of unique parameters for a list of variable objects\n",
    "    :param network_variables: A list of tf network variable objects\n",
    "    :param name: Name of the network\n",
    "    \"\"\"\n",
    "    total_parameters = 0\n",
    "    for variable in network_variables:\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parametes = 1\n",
    "        for dim in shape:\n",
    "            variable_parametes *= dim.value\n",
    "\n",
    "        total_parameters += variable_parametes\n",
    "    print(name, total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UResNetGenerator:\n",
    "    def __init__(self, layer_sizes, layer_padding, batch_size, num_channels=1,\n",
    "                 inner_layers=0, name=\"g\"):\n",
    "        \"\"\"\n",
    "        Initialize a UResNet generator.\n",
    "        :param layer_sizes: A list with the filter sizes for each MultiLayer e.g. [64, 64, 128, 128]\n",
    "        :param layer_padding: A list with the padding type for each layer e.g. [\"SAME\", \"SAME\", \"SAME\", \"SAME\"]\n",
    "        :param batch_size: An integer indicating the batch size\n",
    "        :param num_channels: An integer indicating the number of input channels\n",
    "        :param inner_layers: An integer indicating the number of inner layers per MultiLayer\n",
    "        \"\"\"\n",
    "        self.reuse = False\n",
    "        self.batch_size = batch_size\n",
    "        self.num_channels = num_channels\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.layer_padding = layer_padding\n",
    "        self.inner_layers = inner_layers\n",
    "        self.conv_layer_num = 0\n",
    "        self.build = True\n",
    "        self.name = name\n",
    "        self.encoder_layers = []\n",
    "        self.decoder_layers = []\n",
    "        self.num_filters = 8\n",
    "        self.batch_norm_params = {'decay' : 0.99, 'scale' : True, 'center' : True,\n",
    "                                 'is_training' : False, 'renorm' : True}\n",
    "        \n",
    "    def upscale(self, x, h_size, w_size):\n",
    "        \"\"\"\n",
    "        Upscales an image using nearest neighbour\n",
    "        :param x: Input image\n",
    "        :param h_size: Image height size\n",
    "        :param w_size: Image width size\n",
    "        :return: Upscaled image\n",
    "        \"\"\"\n",
    "        [b, h, w, c] = [int(dim) for dim in x.get_shape()]\n",
    "\n",
    "        return tf.image.resize_nearest_neighbor(x, (h_size, w_size))\n",
    "    \n",
    "    def encoder_block(self, x1, num): \n",
    "        #with tf.variable_scope(scope +'/encoder_block'):\n",
    "        with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n",
    "                            num_outputs = 64, padding = 'SAME',\n",
    "                            kernel_size = [3,3], stride = (1,1),\n",
    "                            activation_fn = tf.nn.leaky_relu,\n",
    "                            normalizer_fn=slim.batch_norm, normalizer_params= self.batch_norm_params):\n",
    "\n",
    "            conv1_1 = slim.conv2d(x1)\n",
    "            output1_1 = tf.concat([conv1_1, x1], axis=3)\n",
    "\n",
    "            conv1_2 = slim.conv2d(output1_1)\n",
    "            output1_2 = tf.concat([conv1_2, output1_1], axis=3)\n",
    "\n",
    "            conv1_3 = slim.conv2d(output1_2)\n",
    "            output1_3 = tf.concat([conv1_3, output1_2], axis=3)\n",
    "\n",
    "            conv1_4 = slim.conv2d(output1_3, stride=(2,2))\n",
    "            output = slim.dropout(conv1_4, keep_prob=0.5)\n",
    "            self.encoder_layers.append(output)\n",
    "\n",
    "            if num == 3:\n",
    "                pass\n",
    "            else :\n",
    "                input_projection = slim.conv2d(conv1_3, num_outputs=conv1_3.get_shape()[3], stride=(2,2),\n",
    "                                               activation_fn= None, normalizer_fn= None)\n",
    "                output = tf.concat([output, input_projection], axis=3)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def decoder_block(self, x1): \n",
    "        with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n",
    "                            num_outputs = 64, padding = 'SAME',\n",
    "                            kernel_size = [3,3], stride = (1,1),\n",
    "                            activation_fn = tf.nn.leaky_relu,\n",
    "                            normalizer_fn=slim.batch_norm, normalizer_params= self.batch_norm_params):\n",
    "\n",
    "            conv1_1 = slim.conv2d(x1)\n",
    "            output1_1 = tf.concat([conv1_1, x1], axis=3)\n",
    "            \n",
    "\n",
    "            conv1_2 = slim.conv2d(output1_1)\n",
    "            output1_2 = tf.concat([conv1_2, output1_1], axis=3)\n",
    "            \n",
    "\n",
    "            conv1_3 = slim.conv2d(output1_2)\n",
    "            output1_3 = tf.concat([conv1_3, output1_2], axis=3)\n",
    "            \n",
    "            conv1_4 = slim.conv2d_transpose(output1_3, stride=(2,2))\n",
    "            self.decoder_layers.append(conv1_4)\n",
    "            output = slim.dropout(conv1_4, keep_prob=0.5)\n",
    "\n",
    "            input_projection = slim.conv2d_transpose(conv1_3, num_outputs=conv1_3.get_shape()[3], stride=(2,2),\n",
    "                                           activation_fn= None, normalizer_fn= None)\n",
    "            output = tf.concat([output, input_projection], axis=3)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def z_noise_concat(self, inputs, z_inputs, h, w):\n",
    "        z_dense = tf.layers.dense(z_inputs, h*w*self.num_filters)\n",
    "        z_noise = tf.reshape(z_dense, [self.batch_size, h, w, self.num_filters])\n",
    "        z_noise_concat = tf.concat([inputs, z_noise], axis= 3)\n",
    "        \n",
    "        self.num_filters = np.int(self.num_filters / 2)\n",
    "        \n",
    "        return z_noise_concat\n",
    "    \n",
    "        \n",
    "    def __call__(self, z_inputs, conditional_input, training=False, dropout_rate=0.0):\n",
    "        \"\"\"\n",
    "        Apply network on data.\n",
    "        :param z_inputs: Random noise to inject [batch_size, z_dim]\n",
    "        :param conditional_input: A batch of images to use as conditionals [batch_size, height, width, channels]\n",
    "        :param training: Training placeholder or boolean\n",
    "        :param dropout_rate: Dropout rate placeholder or float\n",
    "        :return: Returns x_g (generated images), encoder_layers(encoder features), decoder_layers(decoder features)\n",
    "        \"\"\"\n",
    "\n",
    "        with tf.variable_scope(self.name, reuse=self.reuse):\n",
    "            # reshape from inputs\n",
    "            conditional_input = tf.convert_to_tensor(conditional_input)\n",
    "            \n",
    "            with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n",
    "                       num_outputs = 64, padding = 'SAME',\n",
    "                        kernel_size = [3,3], stride = (1,1), activation_fn = None):\n",
    "                with tf.variable_scope(self.name + 'first_en_conv'):\n",
    "                    conv = slim.conv2d(conditional_input, stride=(2,2))\n",
    "                    self.encoder_layers.append(conv)\n",
    "                    \n",
    "                    input_projection = slim.conv2d(conditional_input, num_outputs=conditional_input.get_shape()[3], stride=(2,2))\n",
    "                    output1 = tf.concat([conv, input_projection], axis=3)\n",
    "\n",
    "                en1 = self.encoder_block(output1, 1) #[B,7, 7, 64]\n",
    "                en2 = self.encoder_block(en1, 2) #[B,4,4,64]\n",
    "                en3 = self.encoder_block(en2, 3) #[b,2,2,64]\n",
    "                #end encoder\n",
    "                \n",
    "                with tf.variable_scope(self.name + '/First_de_conv'):\n",
    "                    self.decoder_layers.append(en3)\n",
    "                    input_noise = self.z_noise_concat(en3, z_inputs, 2, 2)                #[b,2,2,72]\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/First_de_block'):\n",
    "                    de_conv1 = self.decoder_block(input_noise)                            #[b, 4, 4, 64]\n",
    "                    de_conv1 = tf.concat([de_conv1, self.encoder_layers[2]], axis=3)\n",
    "                    de_conv1_noise = self.z_noise_concat(de_conv1, z_inputs, 4, 4)\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/Second_de_block'):\n",
    "                    de_conv2 = self.decoder_block(de_conv1_noise)                         #[b, 8, 8, 64]\n",
    "                    de_conv2_noise = self.z_noise_concat(de_conv2, z_inputs, 8, 8)\n",
    "                    de_conv2 = self.upscale(de_conv2_noise, 7, 7)\n",
    "                    de_conv2 = tf.concat([de_conv2, self.encoder_layers[1]], axis=3)\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/Third_de_block'):\n",
    "                    de_conv3 = self.decoder_block(de_conv2)                               #[b, 14, 14 ,64]\n",
    "                    de_conv3 = tf.concat([de_conv3, self.encoder_layers[0]], axis=3)\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/Forth_de_block'):\n",
    "                    de_conv4 = self.decoder_block(de_conv3)                               #[b, 28, 28 ,64]\n",
    "                    de_conv4 = tf.concat([de_conv4, conditional_input], axis=3)\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/Last_de_block'):\n",
    "                    de_conv5_1 = slim.conv2d(de_conv4)\n",
    "                    de_conv5_1 = tf.concat([de_conv5_1, de_conv4], axis=3)\n",
    "                    \n",
    "                    de_conv5_2 = slim.conv2d(de_conv5_1)\n",
    "                    de_conv5_2 = tf.concat([de_conv5_2, de_conv5_1], axis=3)\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/P_process'):\n",
    "                    de_conv = slim.conv2d(de_conv5_2)\n",
    "                    de_conv = slim.conv2d(de_conv, num_outputs = 3)\n",
    "                \n",
    "                with tf.variable_scope('g_tanh'):\n",
    "                    gan_decoder = tf.tanh(de_conv, name='outputs')\n",
    "                \n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)\n",
    "\n",
    "        if self.build:\n",
    "            count_parameters(self.variables, 'generator_parameter_num')\n",
    "        self.build = False\n",
    "        \n",
    "        return gan_decoder, self.encoder_layers, self.decoder_layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = UResNetGenerator([5,5,5,5], [\"SAME\",\"SAME\",\"SAME\",\"SAME\"], [64,64,64,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.random_normal(shape=[16,100], mean=0, stddev=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.zeros(shape=[16,2,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100), Dimension(16)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_de = tf.layers.dense(z, 2*2*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_noise_concat(z_inputs, h, w, num_filters):\n",
    "        z_dense = tf.layers.dense(z_inputs, h*w*num_filters)\n",
    "        z_noise = tf.reshape(z_dense, [16, h, w, num_filters])\n",
    "        #z_noise_concat = tf.concat([inputs, z_noise], axis= 3)\n",
    "        \n",
    "        #self.num_filters = np.int(self.num_filters / 2)\n",
    "        \n",
    "        return z_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_layer=[]\n",
    "h, w, n = 2, 2, 8\n",
    "for i in range(4):\n",
    "    z_dence = tf.layers.dense(z, h*w*n, )\n",
    "    z_noise = tf.reshape(z_dence, [16,h,w,n], )\n",
    "    z_noise\n",
    "    z_layer.append(z_noise)\n",
    "    h = h*2\n",
    "    w = w*2\n",
    "    n = np.int(n/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Reshape_21:0' shape=(16, 2, 2, 8) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_22:0' shape=(16, 4, 4, 4) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_23:0' shape=(16, 8, 8, 2) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_24:0' shape=(16, 16, 16, 1) dtype=float32>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_2:0' shape=(16, 2, 2, 8) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_noise_concat(z, 2,2,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
