{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.zeros(shape=[16,28,28,3])\n",
    "z_input = tf.random_normal([16, 100], mean=0, stddev=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(network_variables, name):\n",
    "    \"\"\"\n",
    "    This method counts the tota\n",
    "    l number of unique parameters for a list of variable objects\n",
    "    :param network_variables: A list of tf network variable objects\n",
    "    :param name: Name of the network\n",
    "    \"\"\"\n",
    "    total_parameters = 0\n",
    "    for variable in network_variables:\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parametes = 1\n",
    "        for dim in shape:\n",
    "            variable_parametes *= dim.value\n",
    "\n",
    "        total_parameters += variable_parametes\n",
    "    print(name, total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UResNetGenerator:\n",
    "    def __init__(self, layer_sizes, layer_padding, batch_size, num_channels=1,\n",
    "                 inner_layers=0, name=\"g\"):\n",
    "        \"\"\"\n",
    "        Initialize a UResNet generator.\n",
    "        :param layer_sizes: A list with the filter sizes for each MultiLayer e.g. [64, 64, 128, 128]\n",
    "        :param layer_padding: A list with the padding type for each layer e.g. [\"SAME\", \"SAME\", \"SAME\", \"SAME\"]\n",
    "        :param batch_size: An integer indicating the batch size\n",
    "        :param num_channels: An integer indicating the number of input channels\n",
    "        :param inner_layers: An integer indicating the number of inner layers per MultiLayer\n",
    "        \"\"\"\n",
    "        self.reuse = False\n",
    "        self.batch_size = batch_size\n",
    "        self.num_channels = num_channels\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.layer_padding = layer_padding\n",
    "        self.inner_layers = inner_layers\n",
    "        self.conv_layer_num = 0\n",
    "        self.build = True\n",
    "        self.name = name\n",
    "        self.encoder_layers = []\n",
    "        self.decoder_layers = []\n",
    "        self.num_filters = 8\n",
    "                \n",
    "    def upscale(self, x, h_size, w_size):\n",
    "        \"\"\"\n",
    "        Upscales an image using nearest neighbour\n",
    "        :param x: Input image\n",
    "        :param h_size: Image height size\n",
    "        :param w_size: Image width size\n",
    "        :return: Upscaled image\n",
    "        \"\"\"\n",
    "        [b, h, w, c] = [int(dim) for dim in x.get_shape()]\n",
    "\n",
    "        return tf.image.resize_nearest_neighbor(x, (h_size, w_size))\n",
    "    \n",
    "    def encoder_block(self, x1, num, scope = None): \n",
    "        with tf.variable_scope(scope +'/encoder_block'):\n",
    "            with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n",
    "                                num_outputs = 64, padding = 'SAME',\n",
    "                                kernel_size = [3,3], stride = (1,1),\n",
    "                                activation_fn = tf.nn.leaky_relu,\n",
    "                                normalizer_fn=slim.batch_norm, normalizer_params= self.batch_norm_params):\n",
    "                \n",
    "                conv1_1 = slim.conv2d(x1)\n",
    "                output1_1 = tf.concat([conv1_1, x1], axis=3)\n",
    "                print(output1_1)\n",
    "\n",
    "                conv1_2 = slim.conv2d(output1_1)\n",
    "                output1_2 = tf.concat([conv1_2, output1_1], axis=3)\n",
    "                print(output1_2)\n",
    "\n",
    "                conv1_3 = slim.conv2d(output1_2)\n",
    "                output1_3 = tf.concat([conv1_3, output1_2], axis=3)\n",
    "                print(output1_3)\n",
    "\n",
    "                conv1_4 = slim.conv2d(output1_3, stride=(2,2))\n",
    "                output = slim.dropout(conv1_4, keep_prob=0.5)\n",
    "                self.encoder_layers.append(output)\n",
    "                print('before inprejec : ', output)\n",
    "                \n",
    "                if num == 3:\n",
    "                    pass\n",
    "                else :\n",
    "                    input_projection = slim.conv2d(conv1_3, num_outputs=conv1_3.get_shape()[3], stride=(2,2),\n",
    "                                                   activation_fn= None, normalizer_fn= None)\n",
    "                    output = tf.concat([output, input_projection], axis=3)\n",
    "                print(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def decoder_block(self, x1): \n",
    "        with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n",
    "                            num_outputs = 64, padding = 'SAME',\n",
    "                            kernel_size = [3,3], stride = (1,1),\n",
    "                            activation_fn = tf.nn.leaky_relu,\n",
    "                            normalizer_fn=slim.batch_norm, normalizer_params= self.batch_norm_params):\n",
    "\n",
    "            conv1_1 = slim.conv2d(x1)\n",
    "            output1_1 = tf.concat([conv1_1, x1], axis=3)\n",
    "            print(output1_1)\n",
    "\n",
    "            conv1_2 = slim.conv2d(output1_1)\n",
    "            output1_2 = tf.concat([conv1_2, output1_1], axis=3)\n",
    "            print(output1_2)\n",
    "\n",
    "            conv1_3 = slim.conv2d(output1_2)\n",
    "            output1_3 = tf.concat([conv1_3, output1_2], axis=3)\n",
    "            print(output1_3)\n",
    "\n",
    "            #output1_3 = self.upscale(output1_3, h, h)\n",
    "            conv1_4 = slim.conv2d_transpose(output1_3, stride=(2,2))\n",
    "            self.decoder_layers.append(conv1_4)\n",
    "            output = slim.dropout(conv1_4, keep_prob=0.5)\n",
    "\n",
    "            input_projection = slim.conv2d_transpose(conv1_3, num_outputs=conv1_3.get_shape()[3], stride=(2,2),\n",
    "                                           activation_fn= None, normalizer_fn= None)\n",
    "            output = tf.concat([output, input_projection], axis=3)\n",
    "            print(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def z_noise_concat(self, inputs, z_inputs, h, w):\n",
    "        z_dense = tf.layers.dense(z_inputs, h*w*self.num_filters)\n",
    "        z_noise = tf.reshape(z_dense, [self.batch_size, h, w, self.num_filters])\n",
    "        z_noise_concat = tf.concat([inputs, z_noise], axis= 3)\n",
    "        \n",
    "        self.num_filters = np.int(self.num_filters / 2)\n",
    "        print(self.num_filters)\n",
    "        \n",
    "        return z_noise_concat\n",
    "    \n",
    "        \n",
    "    def __call__(self, z_inputs, conditional_input, training=False, dropout_rate=0.0):\n",
    "        \"\"\"\n",
    "        Apply network on data.\n",
    "        :param z_inputs: Random noise to inject [batch_size, z_dim]\n",
    "        :param conditional_input: A batch of images to use as conditionals [batch_size, height, width, channels]\n",
    "        :param training: Training placeholder or boolean\n",
    "        :param dropout_rate: Dropout rate placeholder or float\n",
    "        :return: Returns x_g (generated images), encoder_layers(encoder features), decoder_layers(decoder features)\n",
    "        \"\"\"\n",
    "        self.batch_norm_params = {'decay' : 0.99, 'scale' : True, 'center' : True,\n",
    "                                 'is_training' : training, 'renorm' : True}\n",
    "\n",
    "        with tf.variable_scope(self.name, reuse=self.reuse):\n",
    "            # reshape from inputs\n",
    "            conditional_input = tf.convert_to_tensor(conditional_input)\n",
    "            \n",
    "            with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n",
    "                       num_outputs = 64, padding = 'SAME',\n",
    "                        kernel_size = [3,3], stride = (1,1), activation_fn = None):\n",
    "                with tf.variable_scope(self.name + 'first_en_conv'):\n",
    "                    conv = slim.conv2d(conditional_input, stride=(2,2))\n",
    "                    self.encoder_layers.append(conv)\n",
    "                    \n",
    "                    input_projection = slim.conv2d(conditional_input, num_outputs=conditional_input.get_shape()[3], stride=(2,2))\n",
    "                    output1 = tf.concat([conv, input_projection], axis=3)\n",
    "\n",
    "                en1 = self.encoder_block(output1, 1, scope='first_en_block') #[B,7, 7, 64]\n",
    "                en2 = self.encoder_block(en1, 2, scope='second_en_block') #[B,4,4,64]\n",
    "                en3 = self.encoder_block(en2, 3, scope='third_en_block') #[b,2,2,64]\n",
    "                #end encoder\n",
    "                print('end encoder')\n",
    "                print('encoder_layers[0] ', self.encoder_layers[0])\n",
    "                \n",
    "                with tf.variable_scope(self.name + '/First_de_conv'):\n",
    "                    self.decoder_layers.append(en3)\n",
    "                    input_noise = self.z_noise_concat(en3, z_inputs, 2, 2)                #[b,2,2,72]\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/First_de_block'):\n",
    "                    print('input : ' ,input_noise)\n",
    "                    de_conv1 = self.decoder_block(input_noise)                            #[b, 4, 4, 64]\n",
    "                    de_conv1 = tf.concat([de_conv1, self.encoder_layers[2]], axis=3)\n",
    "                    de_conv1_noise = self.z_noise_concat(de_conv1, z_inputs, 4, 4)\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/Second_de_block'):\n",
    "                    de_conv2 = self.decoder_block(de_conv1_noise)                         #[b, 8, 8, 64]\n",
    "                    de_conv2_noise = self.z_noise_concat(de_conv2, z_inputs, 8, 8)\n",
    "                    de_conv2 = self.upscale(de_conv2_noise, 7, 7)\n",
    "                    de_conv2 = tf.concat([de_conv2, self.encoder_layers[1]], axis=3)\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/Third_de_block'):\n",
    "                    de_conv3 = self.decoder_block(de_conv2)                               #[b, 14, 14 ,64]\n",
    "                    de_conv3 = tf.concat([de_conv3, self.encoder_layers[0]], axis=3)\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/Forth_de_block'):\n",
    "                    de_conv4 = self.decoder_block(de_conv3)                               #[b, 28, 28 ,64]\n",
    "                    de_conv4 = tf.concat([de_conv4, conditional_input], axis=3)\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/Last_de_block'):\n",
    "                    de_conv5_1 = slim.conv2d(de_conv4)\n",
    "                    de_conv5_1 = tf.concat([de_conv5_1, de_conv4], axis=3)\n",
    "                    \n",
    "                    de_conv5_2 = slim.conv2d(de_conv5_1)\n",
    "                    de_conv5_2 = tf.concat([de_conv5_2, de_conv5_1], axis=3)\n",
    "                    \n",
    "                with tf.variable_scope(self.name + '/P_process'):\n",
    "                    de_conv = slim.conv2d(de_conv5_2)\n",
    "                    de_conv = slim.conv2d(de_conv)\n",
    "                \n",
    "                with tf.variable_scope('g_tanh'):\n",
    "                    gan_decoder = tf.tanh(de_conv, name='outputs')\n",
    "                \n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)\n",
    "\n",
    "        if self.build:\n",
    "            count_parameters(self.variables, 'generator_parameter_num')\n",
    "        self.build = False\n",
    "        \n",
    "        return gan_decoder, self.encoder_layers, self.decoder_layers        \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = UResNetGenerator([64,64,64,64], ['SAME','SAME','SAME','SAME'], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"g/first_en_block/encoder_block/concat:0\", shape=(16, 14, 14, 131), dtype=float32)\n",
      "Tensor(\"g/first_en_block/encoder_block/concat_1:0\", shape=(16, 14, 14, 195), dtype=float32)\n",
      "Tensor(\"g/first_en_block/encoder_block/concat_2:0\", shape=(16, 14, 14, 259), dtype=float32)\n",
      "before inprejec :  Tensor(\"g/first_en_block/encoder_block/Dropout/dropout_1/mul:0\", shape=(16, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"g/first_en_block/encoder_block/concat_3:0\", shape=(16, 7, 7, 128), dtype=float32)\n",
      "Tensor(\"g/second_en_block/encoder_block/concat:0\", shape=(16, 7, 7, 192), dtype=float32)\n",
      "Tensor(\"g/second_en_block/encoder_block/concat_1:0\", shape=(16, 7, 7, 256), dtype=float32)\n",
      "Tensor(\"g/second_en_block/encoder_block/concat_2:0\", shape=(16, 7, 7, 320), dtype=float32)\n",
      "before inprejec :  Tensor(\"g/second_en_block/encoder_block/Dropout/dropout_1/mul:0\", shape=(16, 4, 4, 64), dtype=float32)\n",
      "Tensor(\"g/second_en_block/encoder_block/concat_3:0\", shape=(16, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"g/third_en_block/encoder_block/concat:0\", shape=(16, 4, 4, 192), dtype=float32)\n",
      "Tensor(\"g/third_en_block/encoder_block/concat_1:0\", shape=(16, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"g/third_en_block/encoder_block/concat_2:0\", shape=(16, 4, 4, 320), dtype=float32)\n",
      "before inprejec :  Tensor(\"g/third_en_block/encoder_block/Dropout/dropout_1/mul:0\", shape=(16, 2, 2, 64), dtype=float32)\n",
      "Tensor(\"g/third_en_block/encoder_block/Dropout/dropout_1/mul:0\", shape=(16, 2, 2, 64), dtype=float32)\n",
      "end encoder\n",
      "encoder_layers[0]  Tensor(\"g/gfirst_en_conv/Conv/BiasAdd:0\", shape=(16, 14, 14, 64), dtype=float32)\n",
      "4\n",
      "input :  Tensor(\"g/g/First_de_conv/concat:0\", shape=(16, 2, 2, 72), dtype=float32)\n",
      "Tensor(\"g/g/First_de_block/concat:0\", shape=(16, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"g/g/First_de_block/concat_1:0\", shape=(16, 2, 2, 200), dtype=float32)\n",
      "Tensor(\"g/g/First_de_block/concat_2:0\", shape=(16, 2, 2, 264), dtype=float32)\n",
      "Tensor(\"g/g/First_de_block/concat_3:0\", shape=(16, 4, 4, 128), dtype=float32)\n",
      "2\n",
      "Tensor(\"g/g/Second_de_block/concat:0\", shape=(16, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"g/g/Second_de_block/concat_1:0\", shape=(16, 4, 4, 324), dtype=float32)\n",
      "Tensor(\"g/g/Second_de_block/concat_2:0\", shape=(16, 4, 4, 388), dtype=float32)\n",
      "Tensor(\"g/g/Second_de_block/concat_3:0\", shape=(16, 8, 8, 128), dtype=float32)\n",
      "1\n",
      "Tensor(\"g/g/Third_de_block/concat:0\", shape=(16, 7, 7, 258), dtype=float32)\n",
      "Tensor(\"g/g/Third_de_block/concat_1:0\", shape=(16, 7, 7, 322), dtype=float32)\n",
      "Tensor(\"g/g/Third_de_block/concat_2:0\", shape=(16, 7, 7, 386), dtype=float32)\n",
      "Tensor(\"g/g/Third_de_block/concat_3:0\", shape=(16, 14, 14, 128), dtype=float32)\n",
      "Tensor(\"g/g/Forth_de_block/concat:0\", shape=(16, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"g/g/Forth_de_block/concat_1:0\", shape=(16, 14, 14, 320), dtype=float32)\n",
      "Tensor(\"g/g/Forth_de_block/concat_2:0\", shape=(16, 14, 14, 384), dtype=float32)\n",
      "Tensor(\"g/g/Forth_de_block/concat_3:0\", shape=(16, 28, 28, 128), dtype=float32)\n",
      "generator_parameter_num 4423028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'g/g_tanh/outputs:0' shape=(16, 28, 28, 64) dtype=float32>,\n",
       " [<tf.Tensor 'g/gfirst_en_conv/Conv/BiasAdd:0' shape=(16, 14, 14, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/first_en_block/encoder_block/Dropout/dropout_1/mul:0' shape=(16, 7, 7, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/second_en_block/encoder_block/Dropout/dropout_1/mul:0' shape=(16, 4, 4, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/third_en_block/encoder_block/Dropout/dropout_1/mul:0' shape=(16, 2, 2, 64) dtype=float32>],\n",
       " [<tf.Tensor 'g/third_en_block/encoder_block/Dropout/dropout_1/mul:0' shape=(16, 2, 2, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/g/First_de_block/Conv2d_transpose/LeakyRelu:0' shape=(16, 4, 4, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/g/Second_de_block/Conv2d_transpose/LeakyRelu:0' shape=(16, 8, 8, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/g/Third_de_block/Conv2d_transpose/LeakyRelu:0' shape=(16, 14, 14, 64) dtype=float32>,\n",
       "  <tf.Tensor 'g/g/Forth_de_block/Conv2d_transpose/LeakyRelu:0' shape=(16, 28, 28, 64) dtype=float32>])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(z_inputs=z_input , conditional_input= x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
