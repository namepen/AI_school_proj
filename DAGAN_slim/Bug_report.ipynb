{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.train.get_or_create_global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.train.get_or_create_global_step()\n",
    "'''\n",
    "Returns and create (if necessary) the global step tensor.\n",
    "\n",
    "Args:\n",
    "graph: The graph in which to create the global step tensor. If missing, use default graph.\n",
    "Returns:\n",
    "The global step tensor.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(t1)\n",
    "    print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Github 연동하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.flags.DEFINE_string -> string으로 정의\n",
    "\n",
    "\n",
    "'''\n",
    "tf.app.flags 로 flags객체에 접근을 할 수 있습니다.\n",
    "\n",
    "이 객체는 기본적으로 제공되는 DEFINE_*** 로 시작되는 함수를 통해서 key, value 형식과 비슷하게 원하는 데이터를 정의할 수 있게 됩니다.\n",
    "\n",
    "출처: http://daeson.tistory.com/256 [대소니]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.flags.DEFINE_string(\"test\", 'hi test', 'hi test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tf.flags.DEFINE_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.image.decode_jpeg\n",
    "\n",
    "'''\n",
    "Decode a JPEG-encoded image to a uint8 tensor.\n",
    "\n",
    "The attr channels indicates the desired number of color channels for the decoded image.\n",
    "\n",
    "Accepted values are:\n",
    "\n",
    "0: Use the number of channels in the JPEG-encoded image.\n",
    "1: output a grayscale image.\n",
    "3: output an RGB image.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flags -> 밖에서 명령어로 불러오기 위해서 사용, 최근에서는 agupaser로 대체해서 사용.\n",
    "명령어로 입력받아서 flag로 받으면 전역변수로 사용가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIL로 이미지 불러오기\n",
    "    - from PIL import Image\n",
    "    - im = Image.open('python.png')\n",
    "    - cropImage = im.crop((100, 100, 150, 150))\n",
    "    - cropImage.save('python-crop.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = Image.open('Downloads/train/img_108.jpg').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = np.asarray(sm)\n",
    "sm = sm / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = sm * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = Image.fromarray(sm.astype('uint8'), 'RGB')\n",
    "#sm.save('test_jpg.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.save('./Downloads/test_jpg.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set()\n",
    "    - set : 집합을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_duplicate_feature_set = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.image.resize_nearset_neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.zeros(shape=[10,28,28,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale(x, h_size, w_size):\n",
    "    [b,h,w,c] = [int(dim) for dim in x.get_shape()]\n",
    "    return tf.image.resize_nearest_neighbor(x, (h_size, w_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscale(x, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_llyers = [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = tf.zeros(shape=[10,26,26,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_llyers.append(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(current_llyers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_llyers[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[b1, h1, w1, d1] = input.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = self.add_encoder_layer(input=outputs, #10,26,26,64\n",
    "                                     training=training,\n",
    "                                     name=\"encoder_layer_{}_{}\".format(i, j),\n",
    "                                     layer_to_skip_connect=current_layers, #list\n",
    "                                     num_features=self.layer_sizes[i],\n",
    "                                     dim_reduce=False,\n",
    "                                     local_inner_layers=encoder_inner_layers, #10,26,26,64\n",
    "                                     dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " [b1, h1, w1, d1] = x_1.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[b0, h0, w0, d0] = x.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.layers.conv2d(x, filters=int(x.get_shape()[3]), kernel_size=[3,3], strides=[2,2], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_inner_layers = [3, 3, 3, 3]\n",
    "generator_layer_padding = [\"SAME\", \"SAME\", \"SAME\", \"SAME\"]\n",
    "generator_layers = [64, 64, 128, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator __call__ 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first\n",
    "    -i ==0, layer_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = x\n",
    "encoder_layers = []\n",
    "current_layers = [outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'zeros:0' shape=(10, 28, 28, 3) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, layer_size in enumerate(self.layer_sizes): -> i =0, layer_size = 64\n",
    "encoder_inner_layers = [outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d/BiasAdd:0\", shape=(10, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"LeakyRelu:0\", shape=(10, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"BatchNorm/batchnorm_1/add_1:0\", shape=(10, 14, 14, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "outputs = tf.layers.conv2d(outputs, filters=64, kernel_size=[3,3], strides=[2,2], \n",
    "                          padding=\"SAME\", activation=None)\n",
    "print(outputs)\n",
    "outputs = tf.nn.leaky_relu(outputs)\n",
    "print(outputs)\n",
    "outputs = tf.contrib.layers.batch_norm(outputs, decay=0.99, scale=True, center=True,\n",
    "                                       is_training=False, renorm=True)\n",
    "print(outputs)\n",
    "current_layers.append(outputs)\n",
    "encoder_inner_layers.append(outputs)\n",
    "encoder_layers.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'zeros:0' shape=(10, 28, 28, 3) dtype=float32>, <tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]\n",
      "[<tf.Tensor 'zeros:0' shape=(10, 28, 28, 3) dtype=float32>, <tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]\n",
      "[<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]\n",
      "Tensor(\"BatchNorm/batchnorm_1/add_1:0\", shape=(10, 14, 14, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(current_layers)\n",
    "print(encoder_inner_layers)\n",
    "print(encoder_layers)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second\n",
    "    -i = 1, layer_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#j = 0\n",
    "outputs = self.add_encoder_layer(input=outputs,\n",
    "                                     training=training,\n",
    "                                     name=\"encoder_layer_{}_{}\".format(i, j),\n",
    "                                     layer_to_skip_connect=current_layers,\n",
    "                                     num_features=self.layer_sizes[i],\n",
    "                                     dim_reduce=False,\n",
    "                                     local_inner_layers=encoder_inner_layers,\n",
    "                                     dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for j in range(self.inner_layers[i]) inner_layers[1] = 3\n",
    "encoder_inner_layers = [outputs]\n",
    "[b1, h1, w1, d1] = outputs.get_shape().as_list()\n",
    "local_inner_layers=encoder_inner_layers\n",
    "layer_to_skip_connect=current_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'zeros:0' shape=(10, 28, 28, 3) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_to_skip_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(layer_to_skip_connect) >= 2:\n",
    "    layer_to_skip_connect = layer_to_skip_connect[-2]\n",
    "else:\n",
    "    layer_to_skip_connect = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'zeros:0' shape=(10, 28, 28, 3) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_to_skip_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b0, h0, w0, d0] = layer_to_skip_connect.get_shape().as_list()\n",
    "h0, h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#크기가 크면 conv2d 연산만 수행(batch_norm,relu 제거)\n",
    "if h0 > h1:\n",
    "    skip_connect_layer = tf.layers.conv2d(inputs=layer_to_skip_connect, filters=int(layer_to_skip_connect.get_shape()[3]), padding= 'SAME',\n",
    "                                        kernel_size=[3, 3], strides=(2, 2))\n",
    "else:\n",
    "    skip_connect_layer = layer_to_skip_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_1/BiasAdd:0\", shape=(10, 14, 14, 3), dtype=float32)\n",
      "Tensor(\"BatchNorm/batchnorm_1/add_1:0\", shape=(10, 14, 14, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(skip_connect_layer)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_layers = [outputs, skip_connect_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_1/BiasAdd:0' shape=(10, 14, 14, 3) dtype=float32>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_inner_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_layers.extend(local_inner_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_1/BiasAdd:0' shape=(10, 14, 14, 3) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(input_features):\n",
    "    \"\"\"\n",
    "    Remove duplicate entries from layer list.\n",
    "    :param input_features: A list of layers\n",
    "    :return: Returns a list of unique feature tensors (i.e. no duplication).\n",
    "    \"\"\"\n",
    "    feature_name_set = set()\n",
    "    non_duplicate_feature_set = []\n",
    "    for feature in input_features:\n",
    "        if feature.name not in feature_name_set:\n",
    "            non_duplicate_feature_set.append(feature)\n",
    "        feature_name_set.add(feature.name)\n",
    "    return non_duplicate_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_layers = remove_duplicates(current_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_1/BiasAdd:0' shape=(10, 14, 14, 3) dtype=float32>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.concat(current_layers, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(10, 14, 14, 67) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"LeakyRelu_1:0\", shape=(10, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"BatchNorm_1/batchnorm/add_1:0\", shape=(10, 14, 14, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#dim_reduce False\n",
    "outputs = tf.layers.conv2d(outputs, filters=64, kernel_size=[3,3], strides=(1,1),\n",
    "                           padding='SAME', activation= None)\n",
    "outputs = tf.nn.leaky_relu(outputs)\n",
    "print(outputs)\n",
    "outputs = tf.contrib.layers.batch_norm(outputs, decay=0.99, scale=True, center=True,\n",
    "                                       is_training=False, renorm=True)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inner_layers.append(outputs)\n",
    "current_layers.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm_1/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inner_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_1/BiasAdd:0' shape=(10, 14, 14, 3) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm_1/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j = 1\n",
    "[b1, h1, w1, d1] = outputs.get_shape().as_list()\n",
    "local_inner_layers=encoder_inner_layers\n",
    "layer_to_skip_connect=current_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm_1/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_inner_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_1/BiasAdd:0' shape=(10, 14, 14, 3) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm_1/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_to_skip_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(layer_to_skip_connect) >= 2:\n",
    "    layer_to_skip_connect = layer_to_skip_connect[-2]\n",
    "else:\n",
    "    layer_to_skip_connect = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_1/BiasAdd:0' shape=(10, 14, 14, 3) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_to_skip_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "[b0, h0, w0, d0] = layer_to_skip_connect.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h1, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_connect_layer = layer_to_skip_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_1/BiasAdd:0' shape=(10, 14, 14, 3) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_connect_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_layers = [outputs, skip_connect_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm_1/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_1/BiasAdd:0' shape=(10, 14, 14, 3) dtype=float32>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_layers.extend(local_inner_layers)\n",
    "current_layers = remove_duplicates(current_layers)\n",
    "outputs = tf.concat(current_layers, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_1:0' shape=(10, 14, 14, 131) dtype=float32>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"LeakyRelu_2:0\", shape=(10, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"BatchNorm_2/batchnorm/add_1:0\", shape=(10, 14, 14, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#dim_reduce False\n",
    "outputs = tf.layers.conv2d(outputs, filters=64, kernel_size=[3,3], strides=(1,1),\n",
    "                           padding='SAME', activation= None)\n",
    "outputs = tf.nn.leaky_relu(outputs)\n",
    "print(outputs)\n",
    "outputs = tf.contrib.layers.batch_norm(outputs, decay=0.99, scale=True, center=True,\n",
    "                                       is_training=False, renorm=True)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'BatchNorm_1/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>, <tf.Tensor 'conv2d_1/BiasAdd:0' shape=(10, 14, 14, 3) dtype=float32>, <tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>, <tf.Tensor 'BatchNorm_2/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "current_layers.append(outputs)\n",
    "print(current_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inner_layers.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j = 2\n",
    "[b1, h1, w1, d1] = outputs.get_shape().as_list()\n",
    "local_inner_layers=encoder_inner_layers\n",
    "layer_to_skip_connect=current_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm_1/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm_2/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_inner_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm_1/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_1/BiasAdd:0' shape=(10, 14, 14, 3) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm_2/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_to_skip_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(layer_to_skip_connect) >= 2:\n",
    "    layer_to_skip_connect = layer_to_skip_connect[-2]\n",
    "else:\n",
    "    layer_to_skip_connect = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_to_skip_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b0, h0, w0, d0] = layer_to_skip_connect.get_shape().as_list()\n",
    "(h0, h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_connect_layer = layer_to_skip_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_layers = [outputs, skip_connect_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'BatchNorm_2/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>,\n",
       " <tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'BatchNorm_2/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>, <tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>, <tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>, <tf.Tensor 'BatchNorm_1/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>, <tf.Tensor 'BatchNorm_2/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]\n",
      "-----------\n",
      "[<tf.Tensor 'BatchNorm_2/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>, <tf.Tensor 'BatchNorm/batchnorm_1/add_1:0' shape=(10, 14, 14, 64) dtype=float32>, <tf.Tensor 'BatchNorm_1/batchnorm/add_1:0' shape=(10, 14, 14, 64) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "current_layers.extend(local_inner_layers)\n",
    "print(current_layers)\n",
    "print('-----------')\n",
    "current_layers = remove_duplicates(current_layers)\n",
    "print(current_layers)\n",
    "outputs = tf.concat(current_layers, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_2:0' shape=(10, 14, 14, 192) dtype=float32>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = tf.zeros(shape=[16,14,14,65*5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_3 = tf.layers.conv2d(x_2, 64, [3,3], (2,2), padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_4 = tf.layers.conv2d(x_3, 64, [3,3], (2,2), padding='SAME')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_5 = tf.layers.conv2d(x_4, 64, [3,3], (2,2), padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_6 = tf.layers.conv2d(x_5, 64, [3,3], (2,2), padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_11/BiasAdd:0' shape=(16, 1, 1, 64) dtype=float32>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_input = tf.random_normal(shape=[64,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_den = tf.layers.dense(z_input, 8*14*14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_3/BiasAdd:0' shape=(64, 1568) dtype=float32>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_5:0' shape=(64, 14, 14, 8) dtype=float32>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(z_den, [64, 14, 14, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
